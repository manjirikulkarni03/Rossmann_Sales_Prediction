{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "448CDAPjqfQr",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "fge-S5ZAYoAp",
        "RoGjAbkUYoAp",
        "iky9q4vBYrdO",
        "QHF8YVU7Yuh3",
        "qYpmQ266Yuh3",
        "bbFf2-_FphqN",
        "Seke61FWphqN",
        "b0JNsNcRphqO",
        "jj7wYXLtphqO",
        "gCFgpxoyphqP",
        "lssrdh5qphqQ",
        "1M8mcRywphqQ",
        "JMzcOPDDphqR",
        "X_VqEhTip1ck",
        "PVzmfK_Ep1ck",
        "ylSl6qgtp1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manjirikulkarni03/Rossmann_Sales_Prediction/blob/main/Retail_Sales_prediction_Manjiri.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual/Team\n",
        "##### **Team Member 1 -**\n",
        "##### **Team Member 2 -**\n",
        "##### **Team Member 3 -**\n",
        "##### **Team Member 4 -**"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied. You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import ensemble\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data='/content/drive/MyDrive/Data & Resources/Rossmann Stores Data.csv'\n",
        "df1=pd.read_csv(data)"
      ],
      "metadata": {
        "id": "q2dNY7-3ZUgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_file='/content/drive/MyDrive/Data & Resources/store.csv'\n",
        "df2=pd.read_csv(data_file)"
      ],
      "metadata": {
        "id": "EVm1HNRhZcr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.tail()"
      ],
      "metadata": {
        "id": "B2oyoR3HZuTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "id": "OCsv2U2QZ6l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.tail()"
      ],
      "metadata": {
        "id": "76IvLfoFZ9wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df1.shape,df2.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df1.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.info()"
      ],
      "metadata": {
        "id": "quuRXr5UaP7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df1.duplicated()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.duplicated()"
      ],
      "metadata": {
        "id": "RLiER717aZ8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.isnull().sum()"
      ],
      "metadata": {
        "id": "t5FCv_gCague"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Percentage of null values in stores_df\n",
        "100*df2.isnull().sum()/df2.shape[0]"
      ],
      "metadata": {
        "id": "l5U4uYXKaoQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.bar(df2)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msno.matrix(df2)"
      ],
      "metadata": {
        "id": "WlRAtLEHcEFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msno.heatmap(df2)"
      ],
      "metadata": {
        "id": "T13euCZocJIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Rossmann dataset is having 1017209 rows and 9 columns while stores dataset is having 1115 rows and 10 columns. \n",
        "2. Store dataset contains null values in total six features. Where CompetitionDistance contains 3 null values,CompetitionOpenSinceMonth and CompetitionOpenSinceYear are having 354 null values,Promo2SinceWeek,Promo2SinceYear and PromoInterval contains 544 null values. While Rossmann dataset does not have any null value.\n",
        "3. There are no duplicate values present in both datasets."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df1.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.columns"
      ],
      "metadata": {
        "id": "FJI0TgfXcUCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df1.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.describe(include='all')"
      ],
      "metadata": {
        "id": "Xp5FD96tcaLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "variables_in_df1=df1.columns.to_list()\n",
        "variables_in_df2=df2.columns.to_list()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rossman_df\n",
        "for i in variables_in_df1:\n",
        "  print('The Unique Values of', i, 'are:', df1[i].unique())"
      ],
      "metadata": {
        "id": "Ps19bLF1cvps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stores_df\n",
        "for i in variables_in_df2:\n",
        "  print('The Unique Values of', i, 'are:', df2[i].unique())"
      ],
      "metadata": {
        "id": "5_dQnYOcc8pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready."
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking Null values from rossman_df dataset:\n",
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "Ojqaq9FLdb1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, there are no null values in rossman_df dataset."
      ],
      "metadata": {
        "id": "ktYcPMfxdugK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking Null values from stores_df dataset:\n",
        "df2.isnull().sum()"
      ],
      "metadata": {
        "id": "VvnQyiyZdqr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dealing with null values from stores_df dataset:\n",
        "df2['CompetitionDistance'].fillna(df2['CompetitionDistance'].median(),inplace=True)\n",
        "df2['CompetitionOpenSinceMonth'].fillna(df2['CompetitionOpenSinceMonth'].mode()[0],inplace=True)\n",
        "df2['CompetitionOpenSinceYear'].fillna(df2['CompetitionOpenSinceYear'].mode()[0],inplace=True)\n",
        "df2['Promo2SinceWeek'].fillna(0,inplace=True)\n",
        "df2['Promo2SinceYear'].fillna(0,inplace=True)\n",
        "df2['PromoInterval'].fillna(0,inplace=True)"
      ],
      "metadata": {
        "id": "2pMDmszHeYCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recheacking null values from stores_df datast:\n",
        "df2.isnull().sum()"
      ],
      "metadata": {
        "id": "T8OJF_Qie1YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msno.bar(df2)"
      ],
      "metadata": {
        "id": "vJWfds99fKso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Successfully converted all null values now."
      ],
      "metadata": {
        "id": "U2pSRQd9fC3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's merge two datasets for getting better results:\n",
        "merged_df=pd.merge(df1,df2,on='Store',how='inner')"
      ],
      "metadata": {
        "id": "JkjvjpD_fTSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.head()"
      ],
      "metadata": {
        "id": "dSJdcH_8fkOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.shape"
      ],
      "metadata": {
        "id": "p2EUNOo9f0QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking dtypes and changing it to int:\n",
        "merged_df.dtypes"
      ],
      "metadata": {
        "id": "TSduA8Pof_bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df[\"Date\"]= pd.to_datetime(merged_df[\"Date\"],format=\"%Y/%m/%d\")\n",
        "merged_df[\"CompetitionDistance\"]= merged_df[\"CompetitionDistance\"].astype(int)\n",
        "merged_df[\"CompetitionOpenSinceMonth\"]= merged_df[\"CompetitionOpenSinceMonth\"].astype(int)\n",
        "merged_df[\"CompetitionOpenSinceYear\"]= merged_df[\"CompetitionOpenSinceYear\"].astype(int)\n",
        "merged_df[\"Promo2SinceWeek\"]= merged_df[\"Promo2SinceWeek\"].astype(int)\n",
        "merged_df[\"Promo2SinceYear\"]= merged_df[\"Promo2SinceYear\"].astype(int)"
      ],
      "metadata": {
        "id": "fbLfeF1YgI5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rechecking dtypes\n",
        "merged_df.dtypes"
      ],
      "metadata": {
        "id": "Lx3oFJrPgMj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['StateHoliday'].value_counts()"
      ],
      "metadata": {
        "id": "UU5zzX-QgkUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['StoreType'].value_counts()"
      ],
      "metadata": {
        "id": "4txjo9TWgmpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['Assortment'].value_counts()"
      ],
      "metadata": {
        "id": "Z15k-VYSguPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['PromoInterval'].value_counts()"
      ],
      "metadata": {
        "id": "qskNIxg2gwnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. As there were missing values in Stores dataset, we started to handle them one by one.\n",
        "2. There were only 3 null values in CompetitionDistance feature and as most of the values are towards the left and the distribution is skewed on the right, we decided to replaced them with median.\n",
        "3. Null values from competitionSinceMonth and competitionSinceMonth are replaced with mode.\n",
        "4. Promo2SinceWeek, Promo2SinceYear and promoInterval is having 544 null values which we have replaced with zero as all the promo2 values corresponding to this are zeros.\n",
        "5. After successfully converting all null values we merged two datasets using inner joint.\n",
        "6. Some features were having diiferent dtypes so converted them to int64."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "#Visualization of distribution of Sales using displot and detecting the outliers through boxplot:\n",
        "fig, ax = plt.subplots(2,1, figsize=(12,7))\n",
        "sns.distplot(merged_df['Sales'],color='firebrick',ax=ax[0])\n",
        "sns.boxplot(x='Sales',data=merged_df, ax=ax[1])"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the distplot visualizations, it is clear that the sales are right skewed."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "#Checking frequency distribution of Sales, CompetitionDistance, Customers and CompetitionOpenSinceYear:\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "#First plot(Sales vs Frequency)\n",
        "plt.subplot(2,2,1)\n",
        "plt.xlabel(\"Sales\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "sns.kdeplot(merged_df[\"Sales\"], color=\"Green\", shade = True)\n",
        "plt.title('Density distribution of Sales',size = 15)\n",
        "\n",
        "#Second plot(CompetitionDistance vs Frequency)\n",
        "plt.subplot(2,2,2)\n",
        "plt.xlabel(\"CompetitionDistance\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "sns.kdeplot(merged_df[\"CompetitionDistance\"], color=\"Green\", shade = True)\n",
        "plt.title('Density distribution of CompetitionDistance',size = 15)\n",
        "\n",
        "#Third plot(Customers vs Frequency)\n",
        "plt.subplot(2,2,3)\n",
        "plt.xlabel(\"Customers\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "sns.kdeplot(merged_df[\"Customers\"], color=\"Green\", shade = True)\n",
        "plt.title('Density distribution of Customers',size = 15)\n",
        "\n",
        "#Forth plot(CompetitionOpenSinceYear vs Frequency)\n",
        "plt.subplot(2,2,4)\n",
        "plt.xlabel(\"CompetitionOpenSinceYear\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "sns.kdeplot(merged_df[\"CompetitionOpenSinceYear\"], color=\"Green\", shade = True)\n",
        "plt.title('Density distribution of CompetitionOpenSinceYear',size = 15)\n",
        "\n",
        "plt.subplots_adjust(left=0.2, bottom=0.2, right=0.9, top=0.9, wspace=0.2, hspace=0.4)"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "#What is percentage of Promoted and Non-promoted store:\n",
        "plt.pie(merged_df['Promo'].value_counts(), labels = merged_df['Promo'].unique(),autopct='%1.1f%%',)\n",
        "plt.legend(title = \"Promo vs Sales :\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above pie chart, we can conclude that most of the stores are promoted(Approx 62%)"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "#Effect of Promo on Sales and customers:\n",
        "plt.subplot(1,2,1)\n",
        "sns.barplot(x=merged_df[\"Promo\"],y=merged_df['Sales'])\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.barplot(x=merged_df[\"Promo\"],y=merged_df['Customers'])"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that both Sales and Customers increases by a significant amount during Promotions. This shows that Promotion has a positive effect for a store."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "#Relation betwwen DayOfWeek with Sales and Customers:\n",
        "plt.subplot(1,2,1)\n",
        "sns.barplot(x=merged_df[\"DayOfWeek\"],y=merged_df['Sales'])\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.barplot(x=merged_df[\"DayOfWeek\"],y=merged_df['Customers'])"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we observe that Sales and Customers are both very less on Sundays as most of the stores are closed on Sunday.\n",
        "\n",
        "Also, Sales on Monday is highest in whole week. This might be due to the fact that stores are closed on Sundays."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "#How state and school holidays affect sales and customers:\n",
        "plt.subplot(1,2,1)\n",
        "sns.barplot(x=merged_df[\"SchoolHoliday\"],y=merged_df['Sales'])\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.barplot(x=merged_df[\"SchoolHoliday\"],y=merged_df['Customers'])"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting '0' (String value) with 0 (int)\n",
        "merged_df['StateHoliday']=merged_df['StateHoliday'].replace('0',0)"
      ],
      "metadata": {
        "id": "upztbA7jYzwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1,2,1)\n",
        "sns.barplot(x=merged_df[\"StateHoliday\"],y=merged_df['Sales'])\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.barplot(x=merged_df[\"StateHoliday\"],y=merged_df['Customers'])"
      ],
      "metadata": {
        "id": "JqWtM9AdY0ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that most of the stores remain closed during State and School Holidays. But it is interesting to note that the number of stores opened during School Holidays were more than that were opened during State Holidays.\n",
        "\n",
        "Another important thing to note is that the stores which were opened during School holidays had more sales than normal."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "#Frequency distribution of CompetitionDistance and CompetitionOpenSinceYear:\n",
        "plt.subplot(1,2,1)\n",
        "sns.distplot(x=merged_df['CompetitionDistance'], hist = True)\n",
        "plt.xlabel('Competition Distance Distribution Plot')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.distplot(x=merged_df['CompetitionOpenSinceYear'], hist = True)\n",
        "plt.xlabel('CompetitionOpenSinceYear Distribution Plot')"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "most of the values of the CompetitionDistance are towards the left and the distribution is skewed on the right. While CompetitionOpenSinceYear is left skewed."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "sns.barplot(x=merged_df[\"Open\"],y=merged_df['Sales'],hue=merged_df[\"DayOfWeek\"])"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows that, when stores are open then sale is more on monday and sunday."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hKulJtVrWlkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "#Assortment vs Sales:\n",
        "sns.barplot(x=merged_df[\"Assortment\"],y=merged_df['Sales'])"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be seen that Assortment B is having highest sale than others."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "#let's explore store type a bit and it's influence on sales and customers:\n",
        "store_type = merged_df.groupby(\"StoreType\")[\"Sales\",\"Customers\"].sum().reset_index()\n",
        "store_type.sort_values([\"Sales\",\"Customers\"], ascending= False, inplace = True) # sorting into descending order to get higher values\n",
        "store_type"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.groupby(\"StoreType\")[\"Sales\"].sum().plot.pie(title='Store Type and Sales', legend=True, autopct='%1.1f%%', shadow=True)\n",
        "plt.show()\n",
        "#customers and store type\n",
        "merged_df.groupby(\"StoreType\")[\"Customers\"].sum().plot.pie(title='Customer Share', legend=True, autopct='%1.1f%%', shadow=True)\n",
        "plt.show()\n",
        "#store types in all of the dataset\n",
        "merged_df[\"StoreType\"].value_counts().plot.pie(title='Share of Store Types', legend=True, autopct='%1.1f%%', shadow=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b8e1F8wFXBwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that stores of type A has higher amount of total Customers and Sales. StoreType D goes on the second place in both Sales and Customers."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "#How sales and customers are related?\n",
        "sns.scatterplot(x=merged_df['Customers'], y=merged_df['Sales'])"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sales and Customer scatter plot shows a direct positive relation between them with a few outliers."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "#How sales and CompetitionDistance are related?\n",
        "sns.scatterplot(x=merged_df['CompetitionDistance'], y=merged_df['Sales'])"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above scatter plot it can be observed that mostly the competitor stores weren't that far from each other and the stores densely located near each other saw more sales."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot "
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1- Null Hypothesis - There is no relation between PromoOpen and Sales\n",
        "\n",
        "Alternate Hypothesis - There is a relationship between promoOpen and sales\n",
        "\n",
        "2- Null Hypothesis - There is no relation between Customers and Sales\n",
        "\n",
        "Alternate Hypothesis - There is a relationship between Customers and sales\n",
        "\n",
        "3- Null Hypothesis - There is no relation between Customers and Sales\n",
        "\n",
        "Alternate Hypothesis - There is a relationship between Customers and sales"
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis - There is no relation between Customers and Sales\n",
        "\n",
        "Alternate Hypothesis - There is a relationship between Customers and sales"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKN4372vF0xF"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import pearsonr\n",
        "first_sample = merged_df[\"Customers\"].head(60)\n",
        "second_sample = merged_df[\"Sales\"].head(60)\n",
        "\n",
        "stat, p = pearsonr(first_sample, second_sample)\n",
        "print('stat=%.3f, p = %.2f'%(stat, p))\n",
        "if p> 0.05:\n",
        "  print('Accept Null Hypothesis')\n",
        "else:\n",
        "  print('Rejected Null Hypothesis')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson Correlation"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the relationship between the testing series"
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis - There is no relation between CompetitionDistance and Sales\n",
        "\n",
        "Alternate Hypothesis - There is a relationship between CompetitionDistance and sales"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2d6QqxGG5GH"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import pearsonr\n",
        "first_sample = merged_df[\"CompetitionDistance\"].head(60)\n",
        "second_sample = merged_df[\"Sales\"].head(60)\n",
        "\n",
        "stat, p = pearsonr(first_sample, second_sample)\n",
        "print('stat=%.3f, p = %.2f'%(stat, p))\n",
        "if p> 0.05:\n",
        "  print('Accept Null Hypothesis')\n",
        "else:\n",
        "  print('Rejected Null Hypothesis')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson Correlation"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the relationship between the testing series"
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis - There is no relation between CompetitionDistance and Sales\n",
        "\n",
        "Alternate Hypothesis - There is a relationship between CompetitionDistance and sales"
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aWUvIhMZq2g"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import pearsonr\n",
        "first_sample = merged_df[\"CompetitionDistance\"].head(60)\n",
        "second_sample = merged_df[\"Sales\"].head(60)\n",
        "\n",
        "stat, p = pearsonr(first_sample, second_sample)\n",
        "print('stat=%.3f, p = %.2f'%(stat, p))\n",
        "if p> 0.05:\n",
        "  print('Accept Null Hypothesis')\n",
        "else:\n",
        "  print('Rejected Null Hypothesis')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson Correlation"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the relationship between the testing series"
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaZUDZBYxF2K"
      },
      "source": [
        "**Univariate analysis of Outliers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsoW4vQCw8p5"
      },
      "outputs": [],
      "source": [
        "merged_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lc8OKwqyxRta"
      },
      "outputs": [],
      "source": [
        "# assigning continous variable features in new variables so that it makes sense while visulatizing through box plots\n",
        "continous_value_feature= [\"DayOfWeek\", \"Sales\", \"Customers\", \"CompetitionDistance\", \"CompetitionOpenSinceMonth\", \"CompetitionOpenSinceYear\", \"Promo2SinceWeek\", \"Promo2SinceYear\"]\n",
        "numeric_features= ['Store', 'DayOfWeek', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek','Promo2SinceYear']\n",
        "categorical_features= [\"Date\", \"StoreType\", \"Assortment\", \"PromoInterval\"]\n",
        "print(\"Numeric_features: \",numeric_features)\n",
        "print(\"Categorical_features: \",categorical_features)\n",
        "print(\"Continous_value_feature: \",continous_value_feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_g2WAclFxY8f"
      },
      "outputs": [],
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "for i in continous_value_feature:\n",
        "  plt.figure(figsize=(15,6))\n",
        "  sns.boxplot(merged_df[i])\n",
        "  plt.title(f\"Box plot for '{i}' feature\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVnrX-ioxklA"
      },
      "outputs": [],
      "source": [
        "#all numeric\n",
        "plt.figure(figsize=(30,15))\n",
        "for n,column in enumerate(continous_value_feature):\n",
        "  plt.subplot(5, 4, n+1)\n",
        "  sns.boxplot(merged_df[column])\n",
        "  plt.title(f'{column.title()}',weight='bold')\n",
        "  plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwsjv9RXxsQZ"
      },
      "source": [
        "From the above box plots we can see clearly the features \"Sales\", \"Customers\", \"CompetitionDistance\", \"CompetitionOpenSinceMonth\" and \"CompetitionOpenSinceYear\" contains several outliers and rest of the features are fine as they are categorical in nature.\n",
        "\n",
        "Let's define a code to detect the number of outliers and percentage of outliers present in each of the feature in order to handle them accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbklAtVExwIB"
      },
      "outputs": [],
      "source": [
        "# defining the code for outlier detection and percentage using IQR.\n",
        "def detect_outliers(data):\n",
        "    outliers = []\n",
        "    data = sorted(data)\n",
        "    q1 = np.percentile(data, 25)\n",
        "    q2 = np.percentile(data, 50)\n",
        "    q3 = np.percentile(data, 75)\n",
        "    print(f\"q1:{q1}, q2:{q2}, q3:{q3}\")\n",
        "\n",
        "    IQR = q3-q1\n",
        "    lwr_bound = q1-(1.5*IQR)\n",
        "    upr_bound = q3+(1.5*IQR)\n",
        "    print(f\"Lower bound: {lwr_bound}, Upper bound: {upr_bound}, IQR: {IQR}\")\n",
        "\n",
        "    for i in data: \n",
        "        if (i<lwr_bound or i>upr_bound):\n",
        "            outliers.append(i)\n",
        "    len_outliers= len(outliers)\n",
        "    print(f\"Total number of outliers are: {len_outliers}\")\n",
        "\n",
        "    print(f\"Total percentage of outlier is: {round(len_outliers*100/len(data),2)} %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEOrbEtpx-PD"
      },
      "outputs": [],
      "source": [
        "# Determining IQR, Lower and Upper bound and number out outliers present in each of the continous numerical feature\n",
        "for feature in continous_value_feature:\n",
        "  print(feature,\":\")\n",
        "  detect_outliers(merged_df[feature])\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDucN1f0yHpi"
      },
      "source": [
        "We have outliers and its percentage in the given features:\n",
        "\n",
        "\"Sales\" - 2.62%\n",
        "\"Customers\" - 3.75%\n",
        "\"CompetitionDistance\" - 9.75%\n",
        "\"CompetitionOpenSinceMonth\" - 1.22%\n",
        "\"CompetitionOpenSinceYear\" - 2.71%\n",
        "Let's define one more function for the outlier treatment using IQR technique and pass the above values to get those values in the IQR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9g7j_MNyLWd"
      },
      "outputs": [],
      "source": [
        "# Defining the function that treats outliers with the IQR technique\n",
        "def treat_outliers_iqr(data):\n",
        "    # Calculate the first and third quartiles\n",
        "    q1, q3 = np.percentile(data, [25, 75])\n",
        "    \n",
        "    # Calculate the interquartile range (IQR)\n",
        "    iqr = q3 - q1\n",
        "    \n",
        "    # Identify the outliers\n",
        "    lower_bound = q1 - (1.5 * iqr)\n",
        "    upper_bound = q3 + (1.5 * iqr)\n",
        "    outliers = [x for x in data if x < lower_bound or x > upper_bound]\n",
        "    \n",
        "    # Treat the outliers (e.g., replace with the nearest quartile value)\n",
        "    treated_data = [q1 if x < lower_bound else q3 if x > upper_bound else x for x in data]\n",
        "    treated_data_int = [int(absolute) for absolute in treated_data]\n",
        "    \n",
        "    return treated_data_int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15S9g-bpyST4"
      },
      "outputs": [],
      "source": [
        "#Passing all the feature one by one from the list of continous_value_feature in our above defined function for outlier treatment\n",
        "for feature in continous_value_feature:\n",
        "  merged_df[feature]= treat_outliers_iqr(merged_df[feature])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKkVmZ6wyZbv"
      },
      "outputs": [],
      "source": [
        "#Replotting the box plots and rechecking the percentage of outliers still available(if any) in the list of continous_value_feature.\n",
        "plt.figure(figsize=(30,15))\n",
        "for n,column in enumerate(continous_value_feature):\n",
        "  plt.subplot(5, 4, n+1)\n",
        "  sns.boxplot(merged_df[column])\n",
        "  plt.title(f'{column.title()}',weight='bold')\n",
        "  plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QX_4ZXdyi3Y"
      },
      "outputs": [],
      "source": [
        "# Rechecking the total number of outliers and its percentage present in our dataset.\n",
        "for feature in continous_value_feature:\n",
        "  print(feature,\":\")\n",
        "  detect_outliers(merged_df[feature])\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ub5y6_Nk0VGU"
      },
      "outputs": [],
      "source": [
        "merged_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH2v65T20VGV"
      },
      "source": [
        "Clearly we have \"StoreType\", \"Assortment\", \"PromoInterval\" as \"object\". To feed them as an input of our Machine Learnning algorithm, we need to use some encoding technique to make dtype of these column as \"integer\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfrCC6-y0VGV"
      },
      "outputs": [],
      "source": [
        "# creating the variable that contains list of \"object\" dtypes\n",
        "obj= [\"StateHoliday\", \"StoreType\", \"Assortment\", \"PromoInterval\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTVu_iXD0VGV"
      },
      "outputs": [],
      "source": [
        "# checking the unique counts of object dype column which is essential to determine the type of encoding to be use in various column\n",
        "for unique in obj:\n",
        "  print(f\"{unique}: \")\n",
        "  print(f\"The unique values are: {merged_df[unique].unique()}\")\n",
        "  print(f\"Total number of unique values are: {merged_df[unique].nunique()}\")\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2X_-30u0VGW"
      },
      "source": [
        "From the above output we can see that the feature \"StateHoliday\" contains \"0\" as string and 0 as int at various observations. we have to label them as 0 can club together as they both are resembling same information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4K935R9P0VGW"
      },
      "outputs": [],
      "source": [
        "# replacing \"0\" to 0 and a=b=c=1 for our simplicity as they resembles that there is holiday\n",
        "merged_df[\"StateHoliday\"].replace({\"0\":0, \"a\":1, \"b\":1, \"c\":1}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJNS1nKt0VGW"
      },
      "outputs": [],
      "source": [
        "# rechecking the unique counts of object dype column which is essential to determine the type of encoding to be use in various column\n",
        "for unique in obj:\n",
        "  print(f\"{unique}: \")\n",
        "  print(f\"The unique values are: {merged_df[unique].unique()}\")\n",
        "  print(f\"Total number of unique values are: {merged_df[unique].nunique()}\")\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q30954F00VGW"
      },
      "source": [
        "Great !!! Our data is ready for the ENCODING.\n",
        "\n",
        "Since we have several encoding techniques but the major ones are:\n",
        "\n",
        "1. Ordinal encoding: Used when the features are ordinal in nature and have some rank between them.\n",
        "2. Nominal encoding: Used when the features have equal weightage and are nominal in nature.\n",
        "\n",
        "As our all the categorical columns are nominal in nature(do not have any rank or order) so will use One-Hot Encoding (Type of Nominal encoding) in our senario:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YL7DppwB0VGW"
      },
      "outputs": [],
      "source": [
        "#Lets create a copy of dataframe to avoid blunders with our original dataframe\n",
        "df_new=merged_df.copy() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KK9UxSG0VGX"
      },
      "source": [
        "We can use the above code to create binary dummy variable for ONE-HOT ENCODING for each of the feature but we will face the issue of \"multicollinearity\" or \"dummy variable trap\" as the information given by the one feature can be explained by the other features and this results in the high \"VIF\". So it better to drop the redundant feature (one category among all other category) here only.\n",
        "\n",
        "We can do this easily by passing the argument \"drop_first = True\" in get_dummies without doing it manually, thanks to python code development team to make our tasks easier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwESiRkM0VGX"
      },
      "outputs": [],
      "source": [
        "# Encode your categorical columns by droppin the first category\n",
        "df_new= pd.get_dummies(merged_df, dtype=int, drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfQ0eOxB0VGX"
      },
      "outputs": [],
      "source": [
        "# code to see all the features\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4KAI9MM0VGX"
      },
      "outputs": [],
      "source": [
        "# Let's see first five observations of our dataset\n",
        "df_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxm2W7oO0VGY"
      },
      "outputs": [],
      "source": [
        "df_new.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYKYqwyM0VGY"
      },
      "source": [
        "**What all categorical encoding techniques have you used & why did you use those techniques?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPSZnvCZ0VGY"
      },
      "source": [
        "a. We have used one-hot encoding technique to change our categorical features of object type into int type by creating their dummies so that it becomes compatible to feed it into various ML algorithms in future.\n",
        "\n",
        "b. Since, we have 3 to 4 unique orderless categories in all the categorical features (which is less in number). So, it is good to use Nominal encoding technique then ordinal."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing \n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2b8tvZ60t0p"
      },
      "outputs": [],
      "source": [
        "# Manipulate Features to minimize feature correlation and create new \n",
        "# Checking the first fir=ve observation of the dataset we have to deal with.\n",
        "df_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oh_rcT5S0t0q"
      },
      "outputs": [],
      "source": [
        "# Extracting date, month and year from Date feature\n",
        "df_new[\"Day\"]= df_new[\"Date\"].dt.day\n",
        "df_new[\"Month\"]= df_new[\"Date\"].dt.month\n",
        "df_new[\"Year\"]= df_new[\"Date\"].dt.year\n",
        "df_new[\"Week\"]= df_new[\"Date\"].dt.week"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XqO41r80t0q"
      },
      "outputs": [],
      "source": [
        "df_new.drop(['Date'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEMpLurm0t0q"
      },
      "outputs": [],
      "source": [
        "df_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRchiids0t0q"
      },
      "outputs": [],
      "source": [
        "# deriving 2 new features:\n",
        "# 1. \"CompetitionOpen -> Duration from which two stores are competiting\"\n",
        "# 2. \"CompetitionOpen -> Duration from which the store is involved in any promotion\"\n",
        "##    Final values are in months.\n",
        "def comp_months(df):\n",
        "    df_new['CompetitionOpen'] = 12 * (df_new.Year - df_new.CompetitionOpenSinceYear) + (df_new.Month - df_new.CompetitionOpenSinceMonth)\n",
        "    df_new['CompetitionOpen'] = df_new['CompetitionOpen'].map(lambda x: 0 if x < 0 else x).fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pp8zJUap0t0q"
      },
      "outputs": [],
      "source": [
        "comp_months(df_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbtRZ-Ny0t0r"
      },
      "outputs": [],
      "source": [
        "df_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PleqmOi0t0r"
      },
      "outputs": [],
      "source": [
        "def promo_cols(df):\n",
        "    # Months since Promo2 was open\n",
        "    df_new['Promo2Open'] = 12 * (df_new.Year - df_new.Promo2SinceYear) +  (df_new.Week - df_new.Promo2SinceWeek)*7/30.5\n",
        "    df_new['Promo2Open'] = df_new['Promo2Open'].map(lambda x: 0 if x < 0 else x).fillna(0) * df_new['Promo2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MztXsOR0t0r"
      },
      "outputs": [],
      "source": [
        "promo_cols(df_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G318v10X0t0r"
      },
      "outputs": [],
      "source": [
        "df_new"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlBDgSF-1Dxb"
      },
      "outputs": [],
      "source": [
        "# Let's see how sales and other features are related\n",
        "for col in df_new.describe().columns.tolist():\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = df_new[col]\n",
        "    label = df_new['Sales']\n",
        "    correlation = feature.corr(label)\n",
        "    sns.scatterplot(x=feature, y=label, color=\"gray\")\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Sales')\n",
        "    ax.set_title('Sales vs ' + col + '- correlation: ' + str(correlation))\n",
        "    z = np.polyfit(df_new[col], df_new['Sales'], 1)\n",
        "    y_hat = np.poly1d(z)(df_new[col])\n",
        "\n",
        "    plt.plot(df_new[col], y_hat, \"r--\", lw=1)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWWWaS4u1Dxb"
      },
      "outputs": [],
      "source": [
        "df_new.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_80EP2p1Dxc"
      },
      "source": [
        "Since, the store was closed for the refurbishment and hence no sales were reported, we can drop the rows where the store is closed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFLA53hV1Dxc"
      },
      "outputs": [],
      "source": [
        "df_final = df_new.drop(df_new[(df_new.Open == 0) & (df_new.Sales == 0)].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_ZhNdpF1Dxc"
      },
      "outputs": [],
      "source": [
        "df_final.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3_SRSLg1Dxd"
      },
      "outputs": [],
      "source": [
        "#let's change the Promo2Open into int again\n",
        "df_final['Promo2Open']= df_final['Promo2Open'].astype(int)\n",
        "df_final.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJMyDc7p1Dxd"
      },
      "outputs": [],
      "source": [
        "# Dropping \"Open\" from our dataset as it is of no use.\n",
        "df_final.drop(columns=[\"Open\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSnj8sUN1Dxd"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "sns.heatmap(abs(round(df_final.corr(),3)), annot=True, cmap=sns.color_palette(\"Set3\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-kytM9f1Dxe"
      },
      "outputs": [],
      "source": [
        "#Multicollinearity\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calc_vif(X):\n",
        "\n",
        "    # Calculating VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "    return(vif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeGYb6511Dxe"
      },
      "outputs": [],
      "source": [
        "# calculating the vif by excluding the redundant features(\"Sales -> Dependent variable\" and \"Store -> ID\")\n",
        "calc_vif(df_final[[i for i in df_final.describe().columns if i not in [\"Store\", \"Sales\", \"Promo2SinceWeek\", \"Promo2SinceYear\", \"CompetitionOpenSinceMonth\", \"CompetitionOpenSinceYear\", \"Month\", \"Year\", \"Week\"]]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yboGH5xC1Dxe"
      },
      "source": [
        "Let's exclude \"Promo2\" as well. As we are getting the exact information from the \"PromoInterval_Jan,Apr,Jul,Oct\", \"PromoInterval_Feb,May,Aug,Nov\", \"PromoInterval_Mar,Jun,Sept,Dec\" features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SS63D7U41Dxf"
      },
      "outputs": [],
      "source": [
        "# calculating the vif by excluding the redundant features(\"Sales -> Dependent variable\" and \"Store -> ID\")\n",
        "calc_vif(df_final[[i for i in df_final.describe().columns if i not in [\"Store\", \"Sales\", \"Promo2SinceWeek\", \"Promo2SinceYear\", \"CompetitionOpenSinceMonth\", \"CompetitionOpenSinceYear\", \"Month\", \"Year\", \"Week\", \"Promo2\"]]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElbyaFoj1Dxf"
      },
      "source": [
        "Great !!! We are getting very good VIF's (Less then 10). Now let's move forward and store the extremely important features in a new dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tYim8uH1Dxf"
      },
      "source": [
        "We can see from the Heatmap the corelation of \"CompetitionDuration\" and \"PromoDuration\" with \"Sales\" is very less so we will not take them into consideration."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HusKhYN9ehRh"
      },
      "outputs": [],
      "source": [
        "#importing all libraries\n",
        "from scipy.stats import zscore\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score as r2, mean_squared_error as mse\n",
        "import math\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSO1b5QuV5NZ"
      },
      "outputs": [],
      "source": [
        "# Importing LinearRegression from sklearn\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieBkj2gv1llC"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "linear_regressor= LinearRegression()\n",
        "# defining dependent variable\n",
        "dependent_variables = 'Sales'\n",
        "# defining independent variable\n",
        "independent_variables = list(df_final.columns.drop(['Sales']))\n",
        "# Create the data of independent variables\n",
        "X = df_final[independent_variables].values\n",
        "# Create the data of dependent variable\n",
        "Y = df_final[dependent_variables].values\n",
        "# splitting the dataset\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 0)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "# Fit the Algorithm\n",
        "reg=linear_regressor.fit(X_train,Y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the model\n",
        "reg.score(X_train, Y_train)"
      ],
      "metadata": {
        "id": "HXso7sS4AU-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.coef_"
      ],
      "metadata": {
        "id": "4TJtaeJGApI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.intercept_"
      ],
      "metadata": {
        "id": "2lkL-1nYAs80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = reg.predict(X_test)\n",
        "Y_pred"
      ],
      "metadata": {
        "id": "aammg68QAv5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred_train = reg.predict(X_train)\n",
        "Y_pred_train"
      ],
      "metadata": {
        "id": "kwxwtHnxA0G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test"
      ],
      "metadata": {
        "id": "0xiMuUdPBCfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train"
      ],
      "metadata": {
        "id": "uZJjtBoeBHCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "#training r2score\n",
        "r2 = r2_score(Y_train, Y_pred_train)\n",
        "print(\"R2 :\" ,r2)"
      ],
      "metadata": {
        "id": "POfn_LiH1ue0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing r2score\n",
        "r2 = r2_score(Y_test, Y_pred)\n",
        "print(\"R2 :\" ,r2)"
      ],
      "metadata": {
        "id": "nFpCqsOrDgfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Calculating_errors(y_train,y_pred_train,y_test,y_test_pred):\n",
        "  MSE_test  = mean_squared_error(Y_test, Y_pred)\n",
        "  print(\"MSE on test is\" ,MSE_test)\n",
        "  MSE_train  = mean_squared_error(Y_train, Y_pred_train)\n",
        "  print(\"MSE on train is\" ,MSE_train)\n",
        "  RMSE_test = np.sqrt(MSE_test)\n",
        "  print(\"RMSE on test is\" ,RMSE_test)\n",
        "  RMSE_train = np.sqrt(MSE_train)\n",
        "  print(\"RMSE on train is\" ,RMSE_train)\n",
        "  print('Training MAE: {:0.2f}'.format(mean_absolute_error(Y_train, Y_pred_train)))\n",
        "  print('Test MAE: {:0.2f}'.format(mean_absolute_error(Y_test, Y_pred)))"
      ],
      "metadata": {
        "id": "UI0Jqa3LEL0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Calculating_errors(Y_train,Y_pred_train,Y_test, Y_pred)"
      ],
      "metadata": {
        "id": "6BjSkq4jEyA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "from sklearn.linear_model import Ridge\n",
        "ridge = Ridge()\n",
        "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "# Fit the Algorithm\n",
        "ridge_regressor.fit(X_train,Y_train)\n",
        "print(\"The best fit alpha value is found out to be :\" ,ridge_regressor.best_params_)\n",
        "print(\"\\nUsing \",ridge_regressor.best_params_, \" the negative mean squared error is: \", ridge_regressor.best_score_)"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "Y_pred_ridge = ridge_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "GL19URMxGmkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE  = mean_squared_error(Y_test, Y_pred_ridge)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score(Y_test, Y_pred_ridge)\n",
        "print(\"R2 :\" ,r2)"
      ],
      "metadata": {
        "id": "jC70bP4FG6k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Adjusted R2 : \",1-(1-r2_score(Y_test, Y_pred_ridge))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "3xYT0CxxHHXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV"
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No improvement in adjusted r2 is seen"
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_dd_aQru0La"
      },
      "source": [
        "**LASSO**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "from sklearn.linear_model import Lasso\n",
        "lasso = Lasso()\n",
        "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "# Fit the Algorithm\n",
        "lasso_regressor.fit(X_train,Y_train)\n",
        "print(\"The best fit alpha value is found out to be :\" ,lasso_regressor.best_params_)\n",
        "print(\"\\nUsing \",lasso_regressor.best_params_, \" the negative mean squared error is: \", lasso_regressor.best_score_)"
      ],
      "metadata": {
        "id": "o55oHToUIW-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "Y_pred_lasso = lasso_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "1zUb4V1hJIWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE  = mean_squared_error(Y_test, Y_pred_ridge)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score(Y_test, Y_pred_lasso)\n",
        "print(\"R2 :\" ,r2)"
      ],
      "metadata": {
        "id": "IpPhWwnTJPx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Adjusted R2 : \",1-(1-r2_score(Y_test, Y_pred_lasso))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "MMu6TxdDJZTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "6cBcSnT4K3HL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV\n",
        "\n"
      ],
      "metadata": {
        "id": "pQ16jC-SK3HU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "o68Y6SwHK3HV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No improvement in adjusted r2 is seen"
      ],
      "metadata": {
        "id": "eod3ndmhK3HW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}